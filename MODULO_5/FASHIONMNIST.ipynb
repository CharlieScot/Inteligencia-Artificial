{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Fashion-MNIST es un conjunto de datos utilizado comúnmente en el campo del aprendizaje automático y la visión por computadora. Es una variante del conjunto de datos MNIST (Modified National Institute of Standards and Technology) original, que es ampliamente utilizado para ejemplos y pruebas en el campo del aprendizaje automático. Mientras que el MNIST original contiene imágenes de dígitos escritos a mano (0 a 9), Fashion-MNIST se compone de imágenes de artículos de moda.\n",
        "\n",
        "Características principales de Fashion-MNIST:\n",
        "\n",
        "Imágenes: Contiene 70,000 imágenes en escala de grises. Cada imagen tiene una resolución de 28x28 píxeles.\n",
        "\n",
        "Categorías: Hay 10 categorías de ropa y accesorios, como camisetas/tops, pantalones, abrigos, vestidos, zapatillas, etc.\n",
        "\n",
        "Conjunto de datos dividido: Se divide típicamente en un conjunto de entrenamiento de 60,000 imágenes y un conjunto de prueba de 10,000 imágenes.\n",
        "\n",
        "Propósito: Fue creado como un reemplazo más desafiante para el conjunto de datos MNIST original. Las categorías de ropa presentan una complejidad mayor en comparación con los dígitos escritos a mano del MNIST.\n",
        "\n",
        "Uso en TensorFlow: En TensorFlow, se utiliza comúnmente para demostrar algoritmos de clasificación y redes neuronales. Se puede cargar fácilmente utilizando las API de TensorFlow.\n",
        "\n",
        "Fashion-MNIST es especialmente útil para aquellos que comienzan en el campo del aprendizaje automático, ya que proporciona un conjunto de datos más interesante y desafiante que el MNIST original, pero sigue siendo lo suficientemente pequeño y manejable para experimentos y pruebas rápidas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HRsi6JhmxAfG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LwVlmKHkmQB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cargar datos\n",
        "(train_images, train_labels), (test_images, test_labels)=fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDcRpm56otnP",
        "outputId": "1e4e230e-fffd-4ffe-8899-711f74a848a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalizar los datos\n",
        "# este código normaliza los datos de las imágenes de entrenamiento y prueba\n",
        "# dividiéndolos por 255. Esto transforma los valores de los píxeles de un rango\n",
        "# de 0-255 a un rango de 0-1, facilitando el proceso de aprendizaje del modelo.\n",
        "#Estas imágenes suelen estar en formato de píxeles, donde cada píxel tiene un\n",
        "#valor de 0 a 255, representando la intensidad de la luz o el color.\n",
        "train_images=train_images/255.0\n",
        "test_images=test_images/255.0"
      ],
      "metadata": {
        "id": "oKPdQzEio_K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resimensionar imagenes para el modelo\n",
        "\n",
        "# Este código se utiliza para cambiar el formato de dos arrays de imágenes,\n",
        "# train_images y test_images, a un formato compatible con una red neuronal\n",
        "# convolucional (CNN).\n",
        "\n",
        "# Formato original:\n",
        "\n",
        "# Tanto train_images como test_images se almacenan inicialmente en un formato\n",
        "# que no es adecuado para el procesamiento por una CNN. Cada imagen es una matriz\n",
        "# de píxeles gris de 28x28, lo que resulta en un array de 28x28x1. Esto significa\n",
        "# que cada imagen se representa por un array aplanado de 784 píxeles.\n",
        "\n",
        "# Formato redimensionado:\n",
        "\n",
        "# La función reshape() se utiliza para cambiar la forma de cada array de imagen a\n",
        "# un formato compatible con una CNN. La nueva forma es (-1, 28, 28, 1). El -1 en\n",
        "# la primera dimensión significa que esta dimensión debe calcularse dinámicamente\n",
        "# en función del número de imágenes en el array. Las dimensiones\n",
        "# restantes (28, 28, 1) representan el ancho, la altura y el número de canales de\n",
        "# cada imagen.\n",
        "\n",
        "#-1, 28, 28, 1) especifica la nueva forma que queremos para el conjunto de datos.\n",
        "# El -1 es un comodín que le dice a Python que ajuste automáticamente esta\n",
        "# dimensión en base a las otras dimensiones y al tamaño total del conjunto de\n",
        "# datos. Esto es útil cuando no sabemos cuántas imágenes hay en train_images,\n",
        "# pero queremos que todas tengan la misma forma.\n",
        "# 28, 28 significa que cada imagen será reajustada para tener 28 píxeles de ancho\n",
        "# por 28 píxeles de alto.\n",
        "# El 1 al final indica que las imágenes son en escala de grises (un solo canal).\n",
        "# Si las imágenes fueran a color (RGB), este número sería 3, representando los\n",
        "#canales rojo, verde y azul.\n",
        "\n",
        "train_images=train_images.reshape((-1, 28, 28, 1))\n",
        "test_images=test_images.reshape((-1, 28, 28, 1))"
      ],
      "metadata": {
        "id": "Za4CVpmFpKEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#construir el modelo\n",
        "# El código model define un modelo de red\n",
        "# neuronal convolucional (CNN) para la tarea de reconocimiento de dígitos escritos\n",
        "# a mano MNIST. Se construye utilizando la API secuencial de Keras, que permite\n",
        "# apilar capas de forma secuencial.\n",
        "\n",
        "# Explicación de las capas:\n",
        "\n",
        "# Conv2D: Esta capa realiza la convolución, la operación fundamental en las CNN.\n",
        "# Toma 32 filtros de tamaño 3x3, aplica una función de activación ReLU (unidad\n",
        "# lineal rectificada) para introducir no linealidad, y especifica la forma de\n",
        "# entrada de los datos (imágenes en escala de grises de 28x28).\n",
        "\n",
        "# MaxPooling2D: Esta capa reduce las dimensiones espaciales de los mapas de\n",
        "# características mediante la realización de una agrupación máxima sobre regiones\n",
        "# de 2x2. Esto ayuda a reducir la complejidad computacional y el sobreajuste.\n",
        "\n",
        "# Dropout: Esta capa elimina aleatoriamente el 25% de las neuronas durante el\n",
        "# entrenamiento, evitando el sobreajuste al hacer que el modelo sea menos sensible\n",
        "# a las neuronas individuales.\n",
        "\n",
        "# Conv2D: Otra capa convolucional con 64 filtros de tamaño 3x3 y activación ReLU.\n",
        "\n",
        "# MaxPooling2D: Otra capa de agrupación máxima para reducir dimensiones.\n",
        "\n",
        "# Dropout: Otra capa de abandono con una tasa de abandono del 25%.\n",
        "\n",
        "# Flatten: Esta capa convierte los mapas de características 2D en un vector 1D,\n",
        "# preparando los datos para las capas totalmente conectadas. Los mapas de\n",
        "# características en redes neuronales profundas son representaciones intermedias\n",
        "# generadas al aplicar filtros a la entrada o a los mapas de características de\n",
        "# capas anteriores. Estos mapas son esenciales para que la red extraiga y aprenda\n",
        "# características progresivamente más complejas y útiles de los datos de entrada.\n",
        "#Los mapas de características en redes neuronales, especialmente en las redes\n",
        "# neuronales convolucionales (CNNs), se pueden entender como matrices. Sin embargo,\n",
        "# es importante tener en cuenta que son matrices tridimensionales. Te explicaré\n",
        "# esto con más detalle:\n",
        "#los mapas de características en CNNs empiezan como matrices bidimensionales\n",
        "# para imágenes en escala de grises, pero rápidamente se convierten en estructuras\n",
        "# tridimensionales a medida que se aplican múltiples filtros, especialmente en el\n",
        "# procesamiento de imágenes a color y en las capas sucesivas de la red.\n",
        "\n",
        "\n",
        "# Dense: Esta capa realiza operaciones completamente conectadas (FC), conectando\n",
        "# esencialmente todas las neuronas de la capa anterior con todas las neuronas de\n",
        "# esta capa. Tiene 128 neuronas y una función de activación ReLU.\n",
        "\n",
        "# Dense: La capa final es otra capa FC con 10 neuronas, que representan los 10\n",
        "# posibles prendas de ropa (0-9). Utiliza una función de activación\n",
        "# softmax, que aplasta la salida en probabilidades, indicando la probabilidad\n",
        "# de cada clase.\n",
        "\n",
        "# En resumen, este modelo CNN utiliza capas convolucionales (Conv2D) para la extracción\n",
        "# de características, capas de agrupación(MaxPooling2D) para la reducción de la dimensionalidad,\n",
        "# capas de abandono (Dropout) para evitar el sobreajuste, Las capas \"Flatten\" en una red\n",
        "# neuronal convolucional (CNN) tienen un propósito muy específico y crucial. Estas\n",
        "# capas se utilizan para convertir los mapas de características tridimensionales\n",
        "# obtenidos de las capas convolucionales y de agrupamiento (MaxPooling2D) en un vector\n",
        "# unidimensional y capas (Dense) totalmente conectadas para\n",
        "# la clasificación. Es un modelo bien estructurado adecuado para la tarea MNIST,\n",
        "# logrando una alta precisión en el reconocimiento de prendas de ropa.\n",
        "\n",
        "model=Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "9DOAzqnKpjhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compilar el modelo\n",
        "#El compile es un método que configura el modelo para el entrenamiento. En esta\n",
        "#etapa, se definen varios parámetros clave que controlan cómo el modelo aprenderá\n",
        "#de los datos.\n",
        "#Antes de que el modelo pueda ser entrenado, necesita ser compilado.\n",
        "#En resumen, este código está preparando un modelo de aprendizaje automático\n",
        "# para el entrenamiento. Selecciona 'Adam' como el método de optimización, usa la\n",
        "# 'sparse categorical crossentropy' como la función de pérdida para un problema de\n",
        "# clasificación multiclase, y seguirá la 'precisión' o 'accuracy' como métrica\n",
        "# para evaluar el rendimiento del modelo.\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GFhkZq3YqdWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#entrenar el modelo\n",
        "#train_images, train_labels:\n",
        "\n",
        "# train_images contiene las imágenes de entrenamiento. Estas son los datos que el\n",
        "# modelo usará para aprender.\n",
        "# train_labels contiene las etiquetas correspondientes a train_images. Estas e\n",
        "# tiquetas son la \"respuesta correcta\" o el resultado que el modelo intentará\n",
        "# predecir. En un escenario de clasificación, por ejemplo, cada imagen tendría una\n",
        "# etiqueta que indica su categoría.\n",
        "\n",
        "# epochs=3:\n",
        "# Un 'epoch' es una iteración completa sobre todo el conjunto de datos de entrenamiento.\n",
        "# epochs=3 significa que el conjunto completo de datos de entrenamiento se pasará\n",
        "# por el modelo un total de tres veces. Cada epoch permite que el modelo aprenda\n",
        "# más sobre los datos, pero más epochs también pueden llevar a un sobreajuste,\n",
        "# donde el modelo se ajusta demasiado a los datos de entrenamiento y no generaliza\n",
        "# bien a nuevos datos.\n",
        "\n",
        "# validation_split=0.2:\n",
        "# Esta opción divide los datos de entrenamiento en dos partes: una para el\n",
        "# entrenamiento real y otra para la validación.\n",
        "# 0.2 significa que el 20% de los datos de entrenamiento se separan para la\n",
        "# validación. Esto no se utiliza para entrenar el modelo, sino para evaluar su\n",
        "# rendimiento en datos que no ha visto durante el entrenamiento. Es una buena\n",
        "# práctica para comprobar si hay sobreajuste.\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=3, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig21o7qjqwNf",
        "outputId": "df322552-e9b3-4cda-e6e5-9af05f8863d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1500/1500 [==============================] - 46s 30ms/step - loss: 0.3526 - accuracy: 0.8686 - val_loss: 0.3212 - val_accuracy: 0.8791\n",
            "Epoch 2/3\n",
            "1500/1500 [==============================] - 49s 32ms/step - loss: 0.3083 - accuracy: 0.8859 - val_loss: 0.2848 - val_accuracy: 0.8963\n",
            "Epoch 3/3\n",
            "1500/1500 [==============================] - 47s 32ms/step - loss: 0.2794 - accuracy: 0.8954 - val_loss: 0.2679 - val_accuracy: 0.9018\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a3fc0538df0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluar el modelo\n",
        "#model.evaluate(...):\n",
        "\n",
        "# model es tu modelo de aprendizaje automático, que ya ha sido entrenado con datos\n",
        "# de entrenamiento.\n",
        "# .evaluate() es un método que se utiliza para evaluar el rendimiento del modelo\n",
        "# en un conjunto de datos separado, en este caso, los datos de prueba.\n",
        "# test_images, test_labels:\n",
        "\n",
        "# test_images contiene las imágenes de prueba. Estas son datos nuevos que el modelo\n",
        "# no ha visto durante su entrenamiento y se utilizan para evaluar qué tan bien el\n",
        "# modelo generaliza a datos no vistos.\n",
        "# test_labels contiene las etiquetas correspondientes a test_images. Estas etiquetas\n",
        "# son la \"respuesta correcta\" para cada imagen de prueba.\n",
        "# test_loss, test_acc = model.evaluate(...):\n",
        "\n",
        "# Cuando ejecutas model.evaluate(), devuelve dos valores: la pérdida de prueba\n",
        "#  (test_loss) y la precisión de prueba (test_acc).\n",
        "# test_loss es el valor de la función de pérdida del modelo en el conjunto de datos\n",
        "# de prueba, que mide cuánto se equivoca el modelo en promedio.\n",
        "# test_acc es la precisión del modelo en el conjunto de datos de prueba, que indica\n",
        "# el porcentaje de etiquetas que el modelo predijo correctamente.\n",
        "\n",
        "test_loss, test_acc=model.evaluate(test_images, test_labels)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUrDmY7eq-du",
        "outputId": "111e4d38-5e58-4990-c393-34cf3ab1db5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2844 - accuracy: 0.8940\n",
            "\n",
            "Test accuracy: 0.8939999938011169\n"
          ]
        }
      ]
    }
  ]
}